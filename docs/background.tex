\chapter{Existing work on the H-Index}
\label{ch:background}

\section{Overview of the H-Index}
The H-Index, introduced by Jorge E. Hirsch in 2005, is a metric designed to
quantify the scientific output and influence of a researcher
\cite{hirsch2005index,hirsch2014meaning,koltun2021h}. It combines productivity,
as measured by the number of publications, with impact, as indicated by the
number of citations these publications receive. Specifically, a researcher has
an H-Index of $h$ if $h$ of their papers have been cited at least $h$ times
each. This index provides a single number that reflects both the quantity and
significance of a researcher’s academic contributions, making it a valuable
tool for evaluating scientific performance
\cite{hirsch2005index,hirsch2014meaning}.

The H-Index quickly gained popularity due to its simplicity and its ability to
balance productivity and citation impact
\cite{hirsch2005index,bornmann2007what,costas2007h,waltman2012inconsistency,hirsch2014meaning,koltun2021h}.
Unlike other metrics that may focus solely on the number of publications or the
total number of citations, it aims to provide a more nuanced measure that
acknowledges both prolific and highly-cited work. This makes it particularly
useful for identifying researchers who consistently produce influential work
over time. It also provides a comparative measure that can be applied across
researchers of similar scientific age and different disciplines, although
adjustments may be needed to account for field-specific citation behaviors
\cite{hirsch2005index,bornmann2007what,costas2007h,egghe2010hirsch}. The
h-index tends to increase over time as more citations accumulate, offering a
cumulative measure of a researcher’s effect on their field. It is less
sensitive to extreme values, mitigating the effect of a few highly cited papers
or numerous low-impact papers, providing a more stable and representative
measure of a researcher's overall effect and remains relevant throughout a
researcher's career, reflecting ongoing contributions
\cite{hirsch2005index,costas2007h,waltman2012inconsistency,egghe2010hirsch}.
This longevity of relevance is beneficial in maintaining a consistent
evaluation metric over time.

The H-index is also useful for evaluating researchers for grants and funding
opportunities. Granting agencies and funding bodies often need to assess the
potential influence and productivity of applicants and the H-index helps in
making these evaluations more consistent and transparent, ensuring that
decisions are based on a quantifiable measure of a researcher's cumulative
contributions
\cite{hirsch2005index,bornmann2007what,costas2007h,waltman2012inconsistency,hirsch2014meaning,koltun2021h}.

In addition to individual evaluations, it can be applied to groups of
researchers, such as departments or research teams. By calculating the
collective h-index of a group, it is possible to assess the overall influence
and productivity of it, which can be useful for internal assessments, strategic
planning, and benchmarking against other institutions or research units
\cite{hirsch2005index,bornmann2007what,costas2007h,waltman2012inconsistency,egghe2010hirsch,hirsch2014meaning,koltun2021h}.
Moreover, it can be used in the context of awards and honors. For instance, it
provides a quantifiable measure to identify candidates for fellowships,
memberships in prestigious academies, and other recognitions. Hirsch suggests
that typical h-index values can be indicative of certain career milestones,
such as achieving tenure, full professorship, or election to the National
Academy of Sciences
\cite{hirsch2005index,bornmann2007what,costas2007h,waltman2012inconsistency,egghe2010hirsch,hirsch2014meaning}.

Lastly, the h-index's application also extends to the evaluation of journals.
It has been used to compare the standing of different scientific journals,
providing a complementary metric to traditional impact factors. This has proven
useful in fields where they may not fully represent a journal's significance or
relevance \cite{norris2010h}.

Despite its advantages and widespread use, the h-index has several notable
limitations and drawbacks that must be considered. One significant issue is its
inability to fully account for the contribution of individual authors in
multi-author papers. Especially, the recent rise in hyperauthorship, where
papers have an extremely large number of co-authors that rarely contribute
equally, has distorted the effectiveness of the h-index which can lead to
researchers with numerous co-authored papers to have an inflated h-index that
does not accurately reflect their individual contributions
\cite{koltun2021h,bihari2018h}. This can lead to misleading evaluations,
especially in fields where large collaborative projects are common
\cite{hirsch2005index,bornmann2007what,costas2007h,waltman2012inconsistency,norris2010h,egghe2010hirsch,hirsch2014meaning}.
Another notable concern is that it reduces the multidimensional space of
bibliometrics into a single dimension, which explains its inconsistency in
ranking scientists \cite{bornmann2007what}.

It is argued that the mechanism used by the h-index to aggregate publication
and citation statistics into a single number can lead to counterintuitive and
inconsistent results \cite{waltman2012inconsistency}. For instance, the h-index
can produce different rankings for scientists who have achieved similar,
relative, or absolute performance improvements. This inconsistency can lead to
situations where a scientist’s ranking relative to another scientist reverses,
despite both achieving the same performance improvement, which is difficult to
justify and undermines the reliability of the h-index as a measure of overall
scientific influence.

Its insensitivity to a few highly cited publications and large numbers of lowly
cited or uncited publications is both a strength and a weakness. While it
avoids overvaluing a small number of "big hits", it can also fail to adequately
recognize the influence of a substantial body of lesser-cited work, which might
be significant in certain niche fields
\cite{hirsch2005index,costas2007h,waltman2012inconsistency,norris2010h,egghe2010hirsch}.
Additionally, it is insensitive to highly cited papers beyond the h-count; once
a paper qualifies to contribute to the h-index, additional citations to that
paper do not affect it, and it also fails to reflect any subsequent reduction
in scholarly influence after the h-index is reached
\cite{hirsch2005index,bornmann2007what,waltman2012inconsistency,norris2010h,egghe2010hirsch,hirsch2014meaning}.
Thus, the h-index also disadvantages researchers with a few significant recent
contributions that have shaped their field but may not have a high overall
publication count. These researchers cannot achieve a high h-index if their
other publications are less cited, leading to an underestimation of their
overall scholarly contributions. This can particularly affect early-career
researchers or those who have made groundbreaking contributions in a limited
number of publications, but are too early in their career for the h-index to
truly illustrate the value of their work, potentially affecting their
opportunities for recognition and advancement
\cite{hirsch2005index,bornmann2007what,costas2007h,waltman2012inconsistency,norris2010h,egghe2010hirsch,hirsch2014meaning}.

Moreover, there are practical challenges in accurately calculating the h-index,
such as difficulties in obtaining a complete record of publications and
citations for researchers with common names, and issues around whether to
include self-citations, which can artificially inflate the measure
\cite{costas2007h,norris2010h,bartneck2011detecting}. Although it is less
susceptible to self-citations than the total citation count, strategic
citations can still artificially inflate it, compromising its reliability as an
objective measure of scientific achievement
\cite{hirsch2005index,bornmann2007what,costas2007h,waltman2012inconsistency,norris2010h,egghe2010hirsch,hirsch2014meaning,bartneck2011detecting}.

Finally, while it aims to balance quantity and quality, it can still favor
researchers who publish frequently over those who produce fewer but more
influential papers
\cite{hirsch2005index,costas2007h,waltman2012inconsistency,norris2010h,egghe2010hirsch,hirsch2014meaning}.
Specifically, it favors researchers in highly cited fields or those who produce
fewer but more papers of significance, while undervaluing those with a larger
volume of work that receives moderate citation counts, which makes it even more
difficult to compare scientists across different disciplines and publication
practices fairly
\cite{hirsch2005index,costas2007h,waltman2012inconsistency,egghe2010hirsch}.

\section{Variants of the H-Index}
\subsection{H-Frac Index}
The h-frac index is an extension of the traditional h-index, designed to
address the distribution of authorship credit in co-authored papers
\cite{egghe2008mathematical}. In order to provide a fairer assessment of
individual contributions in collaborative research, the h-frac index uses
fractional counting methods. There are two main approaches to fractional
counting in the h-frac index: fractional citation counts and fractional paper
counts. Fractional citation counting assigns each author of an $m$-authored
paper a fraction of the citations. For instance, if a paper with $m$ authors
receives $y$ citations, each author gets $y/m$ citations credited. This method
ensures that the total citation credit for a paper does not exceed the actual
citation count. On the other hand, fractional paper counting adjusts the
ranking of papers by giving each author a fractional rank based on the number
of co-authors, for example, an author of an $m$-authored paper contributes
$1/m$ to the rank, rather than a full rank
\cite{egghe2008mathematical,bihari2018h}.

Mathematically, the fractional h-index, denoted as $hf$, is defined as the
largest rank $r$ such that the fractional citation count $y_r/\phi(r)$ is at
least $r$, where $\phi(r)$ is the number of authors of the $r$-th paper in the
ranked list \cite{egghe2008mathematical}. The fractional h-index provides upper
and lower bounds in relation to the traditional h-index. Specifically, $hf$ is
always less than or equal to the traditional h-index ($hf \leq h$), and greater
than or equal to the floor value of the traditional h-index divided by the
maximum number of authors on any paper ($hf \geq \lfloor h / \max(\phi(i))
    \rfloor$) \cite{egghe2008mathematical}.

This way, the h-frac index can provide a more balanced measure of individual
contributions in collaborative works, reflecting a fairer distribution of
credit among co-authors which makes it a valuable tool in academic evaluations,
where collaboration is increasingly prevalent
\cite{egghe2008mathematical,singhal2023analysis}. Another positive aspect of
the h-frac index is its adaptability to different crediting systems, and that
stems from the fact that it can be calculated using either fractional citation
counts or fractional paper counts, allowing for flexibility depending on the
specific context or preferences of the evaluators. The above feature also helps
in creating a level playing field for researchers from different disciplines.
Citation practices can vary widely between fields, and the traditional h-index
does not account for these differences. The fractional allocation of citations
in the h-frac index helps to mitigate these disparities, regardless of the
field \cite{singhal2023analysis}.

While the h-frac index provides a more nuanced approach to measuring individual
contributions in co-authored papers, it is not without its limitations. One
significant challenge is the complexity introduced by fractional counting. The
traditional h-index is relatively straightforward to compute and understand,
which contributes to its widespread acceptance and use, but in contrast, the
h-frac index requires additional data on the number of authors per paper and
more intricate calculations, potentially complicating its implementation and
interpretation \cite{egghe2008mathematical,singhal2023analysis}.

Another issue with the h-frac index is the potential for inconsistency in its
application. Different fields and institutions may have varying practices
regarding authorship and credit distribution. As a result, the use of
fractional counting might lead to discrepancies and make cross-disciplinary
comparisons more difficult. This variability could undermine the
standardization that the h-index currently provides across different scientific
domains \cite{egghe2008mathematical,singhal2023analysis}.

Moreover, the h-frac index, like the traditional h-index, still relies heavily
on citation counts as a measure of scholarly influence. Citations can be
influenced by many factors unrelated to the actual quality or contribution of
the work, such as the popularity of the research topic, the size of the
research community, and even self-citations. Unfortunately, fractionalizing the
counts does not fully address these inherent biases in citation-based metrics
\cite{egghe2008mathematical}. Furthermore, the reliance on the h-frac index
could potentially discourage collaboration. Researchers might feel incentivized
to limit their co-authorship to ensure a higher individual score, which could
negatively affect the collaborative nature of scientific research that is often
crucial for scientific advancements \cite{singhal2023analysis}.

The theoretical nature of the fractional bounds can also pose a limitation.
Although the h-frac index provides mathematical bounds, these are based on the
maximum number of authors for any given paper and this reliance on the extreme
values can sometimes produce bounds that are not reflective of the typical
co-authorship patterns within a researcher's body of work, potentially skewing
the evaluation \cite{egghe2008mathematical}. Furthermore, practical
applications have shown that while fractional indexes provide a fairer
assessment, they can sometimes result in non-integer values for the h-index,
and this can be counterintuitive and less interpretable compared to the whole
numbers provided by traditional metrics. For instance, having a fractional
h-index of 1.8333 does not convey the same immediate understanding as an
integer h-index does \cite{egghe2008mathematical}.

Lastly, while the h-frac index aims to address the distribution of credit in
multi-authored papers, it does not necessarily account for the qualitative
aspects of individual contributions. It is usual that in many collaborative
works, not all authors contribute equally; some may have played a more
significant role than others. The h-frac index treats all contributions as
equal fractions, which might not accurately reflect the true impact of each
author’s work \cite{egghe2008mathematical,singhal2023analysis}.

\subsection{Hp Index}
The hp-index metric, proposed theoretically by Egghe \cite{egghe2011single},
builds upon the traditional h-index by considering the h-index of individual
papers to compute the overall h-index of an author. This metric provides a
deeper level of assessment by evaluating not just the total number of citations
but also the influence of each publication authored by a researcher. To
calculate the hp-index, one first determines the h-index for each of an
author's papers which involves identifying the largest number $h$ such that at
least $h$ papers have been cited at least $h$ times each. Subsequently, the
hp-index is computed as the h-index of these individual h-index values
\cite{bihari2018h,singhal2023analysis,egghe2011single}. The formula for the
hp-index is given as:

\[
    hp(X) = H([h_1, h_2, h_3, \ldots, h_n]),
\]

where $H$ is the function to calculate the h-index from a given set of values,
and $h_1, h_2, \ldots, h_n$ are the h-index values of the individual papers
\cite{egghe2011single}.

The hp-index aims to offer a fairer measure of a researcher's influence by
incorporating the quality and sustained impact of their publications. Unlike
the traditional h-index, which can be disproportionately influenced by a few
highly cited papers, the hp-index takes into account the consistent citation
performance of each paper, thereby providing a more comprehensive assessment of
an author’s contributions and identifying researchers whose publications
consistently achieves a high level of recognition across their body of work
\cite{singhal2023hp,singhal2023analysis}.

The hp-index also mitigates issues such as hyperauthorship by giving a more
balanced view of a researcher's influence and helps differentiate between
researchers with high collaboration and those with more individual
contributions \cite{singhal2023hp,singhal2023analysis}. Additionally, the
hp-index offers a unique ranking order for authors, distinguishing it from
other metrics by incorporating an additional layer of citation data, allowing
it to reflect the depth of a researcher's publications. By focusing on the
h-index of individual papers, the hp-index is able to highlight researchers who
maintain a steady impact across their publications, rather than those who may
have a few exceptionally cited papers \cite{singhal2023hp,singhal2023analysis}.

While the hp-index offers several advantages, it also has some drawbacks that
need to be considered. One of the primary negatives is the complexity involved
in its calculation. Unlike the traditional h-index, the it requires an
additional layer of data collection and processing. This added complexity can
make the it more difficult to implement and understand, especially for those
who are not well-versed in bibliometric analysis \cite{singhal2023hp}.

Another potential drawback of the it is its dependence on the availability of
detailed citation data. Accurate calculation of the hp-index requires
comprehensive data on the citations of each paper, which may not always be
readily available or up-to-date in all databases. Additionally, the it might
not fully address the issue of citation distribution across a researcher's
publications. While it considers the h-index of individual papers, it does not
account for variations in citation practices across different fields or the
varying significance of citations. The above restrictions can result in
disparities when comparing researchers from different disciplines or those
whose work spans multiple fields with differing citation norms
\cite{singhal2023hp,singhal2023analysis}.

\subsection{Hp-Frac Index}
Similarly to the hp-index, the hp-frac index is a metric designed to evaluate
the academic impact of researchers that builds on the concept of the hp-index
while also incorporating fractional allocation of credit. This means that for
each paper, the h-index is divided by the number of co-authors, giving a
fractional credit to each author based on their level of contribution
\cite{singhal2023hp}.

To compute the hp-frac index, one first calculates the h-index for each paper
authored by a researcher. Then, these h-indexes are divided by the number of
authors for each corresponding paper, resulting in fractional h-indexes. The
hp-frac index of the author is then determined by calculating the h-index of
these fractional h-indexes. This method provides a more balanced measure of a
researcher's achievements by ensuring that credit is proportionally allocated
among all contributors \cite{singhal2023hp}.

The hp and the hp-frac index have the same strengths and weaknesses, however,
the primary advantage of the hp-frac index that the hp-index does not offer is
that it provides a more equitable evaluation of individual contributions in
collaborative research by assigning fractional credit, mitigating the inflation
of impact metrics \cite{singhal2023hp}.

\subsection{G Index}
The g-index is an alternative to the h-index, developed to provide a more
comprehensive measure of an author's or journal's scientific impact by
considering the citation distribution among top-cited papers. The g-index is
defined as the highest number $g$ of papers that collectively have received at
least $g^2$ citations. This ensures that it considers the overall citation
performance of the most highly cited papers, making it more sensitive to their
citation counts. As a result, the g-index will always be equal to or greater
than the h-index, reflecting a more detailed distribution of citations among
top papers, because the requirement for the it ($\sum_{i=1}^{g} y_i \geq g^2$,
where $y_i$ is the number of citations of the $i$-th paper) is less stringent
\cite{egghe2008mathematical, egghe2006improvement}.

Additionally, the g-index is easy to calculate from the same data used for the
h-index and offers higher variance among authors in the same field, making
comparisons of scientific visibility more apparent and addresses the
limitations of the h-index by incorporating the citation performance of top
articles. That way it provides a more comprehensive measure of scientific
impact and thus helps in more accurately ranking researchers along with
identifying those with truly exceptional contributions
\cite{egghe2008mathematical, egghe2006theory, egghe2006improvement}.

However, one of the primary concerns with the g-index is that it might
overemphasize the importance of highly cited papers. This is because, by
focusing on the total number of citations across top papers, it can
disproportionately reflect the influence of a few extremely well-cited works
which could skew the perception of a researcher's overall contribution,
especially if their citation profile is characterized by a small number of
highly cited papers rather than a more consistent citation pattern across many
publications \cite{egghe2008mathematical}.

In addition to that, the g-index does not entirely solve the issue of
sensitivity to variations in citation practices across different fields. Like
the h-index, it can be influenced by the varying citation behaviors making
cross-disciplinary comparisons challenging without additional context or
normalization \cite{egghe2008mathematical, egghe2006theory,
    egghe2006improvement}. Even in the case of the g-frac index, which is very
similar to the h-frac index but for the case of the g index, this issue is
unaddressed \cite{egghe2008mathematical}.

Another potential issue with it is that it may be more complex to interpret
compared to the h-index. While both indexes are straightforward to calculate,
the g-index's reliance on cumulative citation counts for the top papers may not
be as intuitively understood by those unfamiliar with the concept and can make
it harder for funding bodies or academic committees to readily grasp the
implications of a given g-index score \cite{egghe2008mathematical,
    egghe2006improvement}.

\subsection{O Index}
The o-index is a metric designed to address some of the limitations inherent in
the h-index for ranking scientists. To provide a more balanced assessment, the
o-index is introduced as the geometric mean of the h-index ($h$) and the number
of citations to a researcher's most cited paper ($m$). Mathematically, it is
defined as $o = \sqrt{mh}$. This approach ensures that both the overall
productivity and the significance of the highest impact work are considered.
The o-index is simple to calculate, requiring only two numbers: the h-index and
the citation count of the most cited paper, making it an accessible and
straightforward metric for researchers to use \cite{dorogovtsev2015ranking}.

Studies have shown that the h-index can systematically favor long lists of
modestly cited publications, which can be a disadvantage for researchers with
fewer but highly cited works. By incorporating the most cited paper, the
o-index provides a fairer representation of a scientist's impact, highlighting
substantial contributions more effectively. Data analysis has demonstrated that
the o-index decreases less with an increasing mean number of citations per
paper compared to the h-index, indicating that it better reflects the quality
of research \cite{dorogovtsev2015ranking}.

Moreover, the o-index is more resistant to manipulation through self-citation
or the publication of numerous low-impact papers, making it a more robust and
reliable metric. This resistance to manipulation, combined with its emphasis on
significant research achievements, makes the o-index an appealing alternative
to the h-index \cite{dorogovtsev2015ranking}.

Despite its advantages over the h-index, the o-index seems to have its
drawbacks as well. One potential negative aspect is that it still incorporates
the h-index, which means it partially inherits the limitations associated with
it. For instance, the h-index does not account for the highly skewed nature of
citation distributions, thus, by including it, the o-index may still not fully
capture the breadth of a researcher's contributions
\cite{dorogovtsev2015ranking}. Moreover, although it is resistant to
manipulation, it is still possible for it to be artificially inflated.
Researchers might focus on strategies to boost the citation count of their most
cited paper, potentially through citation circles or self-citations, thus
gaming the system to some extent \cite{dorogovtsev2015ranking}.

\subsection{J Index}
The j-index is a scientometric indicator introduced to address the limitations
of existing indexes such as the h and g-index. The j-index aims to combine the
advantages of both indexes, providing a more balanced measure of a researcher's
scientific impact and is defined as the maximum value $j$ for which $j$ of the
most frequently cited works by an author are cited at least $j^{3/2}$ times.
The j-index is calculated by rounding down $j^{3/2}$ to the nearest integer,
for example, an author has a j-index of 2 if they have at least two articles
cited two or more times each, a j-index of 4 if they have at least four
articles cited eight or more times each, and a j-index of 7 if they have at
least seven articles cited 18 or more times each \cite{mikhailov2014new}.

The j-index offers a middle ground between the h and g-index in terms of
strictness and sensitivity, which allows it to account for both moderately and
highly cited papers, providing a more balanced measure of a researcher's
contributions \cite{mikhailov2014new}. It is also relatively easy to calculate
and understand, making it accessible for broad use in the scientific community
while it does not sacrifice depth, as it still manages to capture the nuances
of citation patterns across different publications. Moreover, the j-index
provides a clearer differentiation among researchers. For instance, it can
distinguish between researchers who have the same h-index but different
citation distributions which is crucial for a fair assessment of scientific
contributions, as it recognizes the varied ways in which researchers could play
a key role in their fields \cite{mikhailov2014new}.

However, as expected, the j-index seems to have the same weaknesses as the
other variants of the h-index that are not fractional. One of the primary
concerns is that, like other citation-based metrics, it does not account for
the position of the researcher in the list of co-authors. This means that a
researcher who is a minor contributor to a highly cited paper might receive the
same credit as the primary author, which can skew the assessment of individual
contributions. Also, the j-index is subject to the same data quality issues
that affect all citation metrics. Inaccuracies in citation databases, such as
missing citations or errors in author attribution, can adversely impact the
calculation of the j-index and can lead to misleading assessments of a
researcher’s achievement \cite{mikhailov2014new}.

\section{Comparative Analysis of the H-Index Variants}
As we have seen, in the pursuit of a comprehensive and equitable assessment of
academic contributions and achievements, several variants of the H-index have
been proposed, each addressing specific limitations of the original metric.
While these variants strive to differentiate themselves from the traditional
H-index, empirical studies have demonstrated high correlation coefficients
among them, suggesting a degree of redundancy in their ability to measure
scientific achievement. Specifically, Bornmann et al. identified that the
indexes essentially fall into two categories: those that describe the most
productive core of a scientist’s output and those that depict the impact of the
papers within that core \cite{bornmann2008are, bornmann2011multilevel}.

Additionally, Bornmann et al.'s 2011 meta-analysis revealed that most h-index
variants exhibit high correlations with the original h-index, typically ranging
between 0.8 and 0.9, suggesting that many variants do not provide noteworthy
information beyond what is captured by the h-index itself. However, studies
have also identified that some variants, such as the m index (which represents
the median number of citations received by papers in the Hirsch core), have
lower correlations with the h-index, indicating that they might offer
non-redundant contributions and could complement the h-index in evaluating
scientific performance \cite{bornmann2011multilevel, bornmann2008are}.

More recently, it was found that the effectiveness of the h-index as a
correlate of reputation has significantly declined over time. For example, in
the field of physics, the correlation between the h-index and scientific awards
dropped from 0.34 in 2010 to 0.00 in 2019. This decline is associated with
changes in authorship patterns, particularly the rise of hyperauthorship
\cite{koltun2021h}. The superiority of fractional allocation measures over
traditional ones was demonstrated and these measures, especially the fractional
analogue of the h-index known as h-frac, show a higher correlation with
scientific awards. In 2019, the h-frac had an average Kendall’s $\tau$ of 0.32,
compared to 0.16 for the h-index. Furthermore, fractional measures maintain
stable predictive power over time. For example, h-frac's average $\tau$ was
0.34 in 1994, 0.36 in 2004, and 0.33 in 2014, whereas the h-index's predictive
power has declined, with an average $\tau$ dropping from 0.32 in 2004 to 0.24
in 2014 \cite{koltun2021h}.

The robustness of these findings is confirmed across multiple scientific fields
(Biology, Computer Science, Economics, and Physics) and two bibliographic
platforms (Scopus and Google Scholar). Additionally, resilience tests using
different correlation statistics (e.g., Kendall’s $\tau$, AUC, Somers’ D,
Goodman and Kruskal’s $\gamma$, and Spearman’s $\rho$) consistently showed the
superior performance of fractional measures. It was also observed that the
correlation between traditional measures and their fractional counterparts has
decreased over time, particularly after 2010. This decline correlates with the
increase in the average number of authors per paper. Detailed case studies
highlight that hyperauthors (those with many coauthors) tend to have high
h-indexes but low h-frac values, indicating that h-frac more accurately
reflects individual contributions \cite{koltun2021h}.

Lastly, a study in 2023 that introduced the hp-frac index, in order to compare
the similarity of the rankings produced by different indexes (h-index,
h-frac-index, hp-index, and hp-frac-index), used the Rank Biased Overlap (RBO)
metric, which quantifies the overlap between two ranked lists, providing
insight into how similarly the indexes rank researchers. The RBO analysis
revealed that the hp-frac-index had the lowest overlap with the traditional
h-index, indicating that it produced a distinct ranking order. Conversely, the
h-index and h-frac-index showed a high degree of overlap, suggesting that
fractional allocation of citations did not significantly alter the rankings
produced by the traditional h-index.

Further analysis focused on the ranking of awarded researchers, where it was
found that the hp-frac-index consistently ranked a higher percentage of awarded
researchers in the top 5\% compared to the h-index and h-frac-index. For
instance, in Biology, 61.5\% of the awarded researchers were ranked in the top
5\% by the hp-frac-index, whereas the h-index only ranked 23.08\% of them in
the top 5\% \cite{singhal2023hp}. Additionally, the overall ranking
distribution of awarded researchers was examined. The hp-frac-index again
outperformed the other indexes by placing a higher proportion of awardees in
the top 20\% of the ranked lists. In conclusion, the latest experimental
analysis demonstrated that the hp-frac-index provides a more robust and
balanced evaluation of research impact compared to the traditional h-index and
its direct variants \cite{singhal2023hp}.

Nevertheless, noteworthy to mention is that many variants of the h-index have
been explored and proposed across time. Despite these developments, the h-index
remains the predominant measure of scientific performance. The persistence of it
can be attributed to several factors. Firstly, it provides a concise summary of
a scientist’s output in a single number, facilitating comparison and ranking.
Secondly, it does not necessitate a minimum number of publications or a
specific career length, making it applicable to scientists at any career stage.
Thirdly, it does not require the adjustment of thresholds or parameters, being
a simple and easy to compute metric. Fourthly, it is straightforward to
interpret for non-experts, making it accessible to a broad audience. Lastly,
criticism notwithstanding, the h-index is still regarded as a reliable measure
of an individual scientist’s influence \cite{koltun2021h}.
