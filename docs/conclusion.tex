\chapter{Conclusion}
\label{ch:conclusion}

Summarize the main contributions of the research and how they address the
research questions or hypotheses. Reflect on the implications of the findings,
the limitations of the study, and suggests areas for future research.

\section{Summary of Contributions}

This research contributes to the field of bibliometrics by addressing
significant limitations in the traditional H-Index through the development and
evaluation of adjusted H-Indexes that incorporate journal quality and subject
specificity. The primary contributions of this study are summarized as follows:

Firstly, the study introduced two new variants of the H-Index: the H5-adjusted
H-Index and the JIF-adjusted H-Index. These metrics incorporate the quality of
journals in which a researcher's works are published, using the H5-Index and
Journal Impact Factor (JIF) to select the top 20\% of journals by rank within
specific subjects. By doing so, the adjusted H-Indexes provide a more accurate
and meaningful measure of a researcher's scholarly impact.

Secondly, the study showcases a robust methodological approach to bibliometric
analysis, leveraging the Alexandria3k tool to extract and analyze publication
data from the Crossref-2024 dataset. The use of ROLAP (Relational Online
Analytical Processing) analysis and rigorous SQL unit testing ensured the
reliability and accuracy of the adjusted H-Index calculations. This methodology
can serve as a framework for future research in bibliometrics and research
evaluation.

Thirdly, through comprehensive statistical analysis, including Pearson,
Spearman, and Kendall tau rank order correlations, the study demonstrated that
the adjusted H-Indexes are significantly correlated with the traditional
H-Index. This strong positive relationship suggests that researchers who rank
highly according to the traditional H-Index also tend to rank highly according
to the adjusted H-Indexes. However, the distinctiveness of the adjusted
H-Indexes, indicated by the imperfect correlation, highlights the meaningful
variations introduced by incorporating journal quality and subject specificity.

Fourthly, the study compared the citation patterns of researchers with high
traditional H-Indexes and those with high adjusted H-Indexes. The analysis
revealed differences in the distribution of citations across journals, with
researchers with high adjusted H-Indexes receiving more citations from journals
with higher impact factors and H5-Indexes. This was particularly evident in
researchers with high H-Indexes from the bottom 50\% of journals by rank, who
exhibited a more pronounced shift in citation patterns, but was also observed
in researchers with high H-Indexes from the top 20\% of journals. This finding
underscores the importance of considering journal quality along with subject
specificity in evaluating scholarly impact and suggests that the adjusted
H-Indexes capture the influence of publishing in higher and lower-quality
journals more effectively than the traditional H-Index.

Fifthly, the findings have important implications for researchers,
practitioners, and policymakers involved in research evaluation and funding
decisions. By incorporating journal quality metrics into evaluation criteria,
the adjusted H-Indexes provide a more comprehensive and fair assessment of a
researcher's impact. This study advocates for the adoption of refined
bibliometric tools that address the limitations of traditional metrics,
ultimately contributing to more accurate and equitable academic evaluations.

Lastly, the study highlights not only the need for further research into
advanced H-Index variants that address issues such as self-citation and
hyperauthorship, but the need for subject-specific analysis of authors, through
their citation patterns and networks. Future work could explore the development
of even more sophisticated H-Index metrics that balance complexity with
usability, enhancing the precision and fairness of bibliometric evaluations,
along with subject-specific citation patterns and their implications for
scholarly impact.

In summary, this research advances the understanding and application of
bibliometric metrics by demonstrating the value of incorporating journal
quality and subject specificity into the calculation of H-Indexes. The adjusted
H-Indexes developed in this study offer a more accurate and meaningful measure
of scholarly impact, providing valuable insights and practical recommendations
for improving research evaluation practices.

\section{Limitations of the Study}

This study, while providing valuable insights into the effectiveness of
adjusted H-Indexes, has several limitations that must be acknowledged.

One significant limitation is the reliance on Crossref-2024 data, which did not
include subject classifications for the journals. To address this, we used the
subject classifications from the previous yearâ€™s data for the journals. This
approach assumes that the subject classifications of journals do not change
significantly from year to year, which may not always be the case.
Additionally, we supplemented missing subject data using the Scopus API, which
introduces another layer of dependency and potential inconsistencies. The
reliance on historical data and external APIs for subject classification could
lead to inaccuracies in the analysis, as some journals might have updated their
scope or focus areas, and new journals may not have been appropriately
classified. Morevover, since the subject classification is based on the journal
level, it may not capture the full range of topics covered by individual
articles within a journal, potentially leading to inaccuracies in the
subject-specific rankings, hence the subjects of works were removed from the
Crossref-2024 dataset.

Although Crossref aims for comprehensive coverage, it is still dependent on the
participation of publishers. Not all publishers might contribute to Crossref,
leading to potential gaps in coverage, especially for publications from less
prominent or niche publishers. As we have seen, different academic disciplines
have varying citation practices and publication norms. While Crossref attempts
to standardize data, the inherent differences in how disciplines publish and
cite work can still lead to discrepancies when comparing H-Index values across
fields.

Moreover, our study filtered the publications to include only those in the top
20\% of journals by subject rank. While this method ensures a focus on
high-quality publications, it may exclude significant contributions from
journals that do not rank in the top 20\% but are still reputable and impactful
within their respective fields. This filtering criterion might bias the results
towards researchers who publish predominantly in highly ranked journals,
potentially overlooking the contributions of those whose work is more niche or
interdisciplinary and published in lower-ranked but still respected journals.

Another limitation is the scope of H-Index variants considered. While we
developed and evaluated adjusted H-Indexes incorporating journal quality
metrics, more advanced H-Index variants could further address issues such as
self-citation and hyperauthorship, which are known to cause H-Index inflation.
Variants like the fractional H-Index, which distributes citation credit more
equitably among co-authors, or metrics that specifically account for
self-citations, with the journal quality adjustment, could provide an even more
refined measure of scholarly impact. Our study did not implement these more
sophisticated variants, which might offer even better adjustments for the
limitations of the traditional H-Index.

To sum up, while our study makes significant strides in refining the H-Index to
account for journal quality and subject specificity, it is constrained by data
limitations, the selection of H-Index variants. Addressing these limitations in
future research could further enhance the accuracy and fairness of bibliometric
evaluations, providing a more robust tool for assessing scholarly impact
overall.